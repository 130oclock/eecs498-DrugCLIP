# EECS 498 Replication Project

## Modules

Always run these when you create a new console on Great Lakes.

```bash
module load cuda/11.8.0
module load python/3.9.12

# Only run once the virtual environment has been created
source ./.venv/bin/activate
```

## Setup

Check that the python version is 3.9.x and are using CUDA 11.8.

```bash
python -V
> Python 3.9.x
nvcc -V
> 11.8.0
```

### Optional for Trying CUDA on Windows

If on windows, install version 17.8 of the Visual C++ Build Tools from this link: https://learn.microsoft.com/en-us/visualstudio/releases/2022/release-history.
Add `C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.38.33130\bin\Hostx64\x64\` to the environment variables.

Then locate `C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.38.33130\include\type_traits` and add the following between lines 1162 and 1163.

```cpp
#define _ENABLE_EXTENDED_ALIGNED_STORAGE
```

### Required

Install the required python packages.

```bash
python -m venv ./.venv/
source ./.venv/bin/activate
pip install -r requirements.txt
pip install torch==2.5.1 --index-url https://download.pytorch.org/whl/cu118
```

Install Uni-Core.

```bash
wget https://github.com/dptech-corp/Uni-Core/archive/refs/tags/0.0.3.zip
unzip Uni-Core-0.0.3
cd Uni-Core-0.0.3
python setup.py install
```

Using the bash scripts does not seem to work on Windows, so instead run the PCBA test using the following command:

```bash
mkdir test
python ./unimol/test.py --user-dir ./unimol $data_path "./data" --valid-subset test --results-path ./test --num-workers 8 --ddp-backend=c10d --batch-size 8 --task drugclip --loss in_batch_softmax --arch drugclip --fp16 --fp16-init-scale 4 --fp16-scale-window 256 --seed 1 --path checkpoint_best.pt --log-interval 100 --log-format simple --max-pocket-atoms 511 --test-task PCBA
```


Original `README.md` below:

# DrugCLIP: Contrastive Protein-Molecule Representation Learning for Virtual Screening

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/xxxx/blob/main/LICENSE)
[![ArXiv](http://img.shields.io/badge/cs.LG-arXiv%3A2310.06367-B31B1B.svg)](https://arxiv.org/pdf/2310.06367.pdf)

<!-- [[Code](xxxx - Overview)] -->

![cover](framework.png)

Official code for the paper "DrugCLIP: Contrastive Protein-Molecule Representation Learning for Virtual Screening", accepted at *Neural Information Processing Systems, 2023*. **Currently the code is a raw version, will be updated ASAP**. If you have any inquiries, feel free to contact billgao0111@gmail.com

# Requirements

same as [Uni-Mol](https://github.com/dptech-corp/Uni-Mol/tree/main/unimol)

**rdkit version should be 2022.9.5**

## Data and checkpoints

https://drive.google.com/drive/folders/1zW1MGpgunynFxTKXC2Q4RgWxZmg6CInV?usp=sharing

It currently includes the train data, the trained checkpoint and the test data for DUD-E



### Training data

The dataset for training is included in google drive: train_no_test_af.zip. It contains several files:

```

dick_pkt.txt: dictionary for pocket atom types

dict_mol.txt: dictionary for molecule atom types

train.lmdb: train dataset

valid.lmdb: validation dataset

```

Use py_scripts/lmdb_utils.py to read the lmdb file. The keys in the lmdb files and corresponding descriptions are shown below:

```

"atoms": "atom types for each atom in the ligand" 

"coordinates": "3D coordinates for each atom in the ligand generated by RDKit. Max number of conformations is 10"

"pocket_atoms": "atom types for each atom in the pocket"

"pocket_coordinates": "3D coordinates for each atom in the pocket"

"mol": "RDKit molecule object for the ligand"

"smi": "SMILES string for the ligand"

"pocket": "pdbid of the pocket",
```


The dataset is compiled from the PBDBind dataset, containing a combination of authentic protein-ligand complexes and those generated through HomoAug, a technique for augmenting data with homology-based transformations.


### Test data

#### DUD-E

```
DUD-E
├── gene id
│   ├── receptor.pdb
│   ├── crystal_ligand.mol2
│   ├── actives_final.ism
│   ├── decoys_final.ism
│   ├── mols.lmdb (containing all actives and decoys)
│   ├── pocket.lmdb

```

#### PCBA

```
lit_pcba
├── target name
│   ├── PDBID_protein.mol2
│   ├── PDBID_ligand.mol2
│   ├── actives.smi
│   ├── inactives.smi
│   ├── mols.lmdb (containing all actives and inactives)
│   ├── pocket.lmdb

```


### Data preprocessing

see py_scripts/write_dude_multi.py

## HomoAug

Please refer to HomoAug directory for details

## Train

bash drugclip.sh

## Test

bash test.sh


## Retrieval 

bash retrieval.sh

In the google drive folder, you can find example file for pocket.lmdb and mols.lmdb under retrieval dir.


## Citation

If you find our work useful, please cite our paper:

```bibtex
@inproceedings{gao2023drugclip,
    author = {Gao, Bowen and Qiang, Bo and Tan, Haichuan and Jia, Yinjun and Ren, Minsi and Lu, Minsi and Liu, Jingjing and Ma, Wei-Ying and Lan, Yanyan},
    title = {DrugCLIP: Contrasive Protein-Molecule Representation Learning for Virtual Screening},
    booktitle = {NeurIPS 2023},
    year = {2023},
    url = {https://openreview.net/forum?id=lAbCgNcxm7},
}
```
